{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f893735",
   "metadata": {},
   "source": [
    "# Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89791993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "477b2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPA_TR = {\n",
    "    \"01_VOLTAJE_AC_DEL_SISTEMA_L1_L2\": \"voltaje_ac_l1_l2\",\n",
    "    \"02_VOLTAJE_AC_DEL_SISTEMA_L2-L3\": \"voltaje_ac_l2_l3\",\n",
    "    \"03_VOLTAJE_AC_DEL_SISTEMA_L3-L1\": \"voltaje_ac_l3_l1\",\n",
    "    \"11_CORRIENTE_AC_DE_LA_CARGA_L1\": \"corriente_ac_l1\",\n",
    "    \"12_CORRIENTE_AC_DE_LA_CARGA_L2\": \"corriente_ac_l2\",\n",
    "    \"13_CORRIENTE_AC_DE_LA_CARGA_L3\": \"corriente_ac_l3\",\n",
    "    \"14_POTENCIA_ACTIVA_DE_LA_CARGA\": \"potencia_activa_kw\",\n",
    "    \"15_POTENCIA_REACTIVA_DE_LA_CARGA\": \"potencia_reactiva_kvar\",\n",
    "    \"16_POTENCIA_APARENTE_DE_LA_CARGA\": \"potencia_aparente_kva\", \n",
    "    \"17_FACTOR_DE_POTENCIA_DE_LA_CARGA\": \"factor_potencia\"\n",
    "}\n",
    "\n",
    "MAPA_ML = {\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_R\": \"corriente_ac_r\",\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_S\": \"corriente_ac_s\",\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_T\": \"corriente_ac_t\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_R-S\": \"voltaje_ac_rs\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_S-T\": \"voltaje_ac_st\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_T-R\": \"voltaje_ac_tr\",\n",
    "    \"ANALOG_INPUT_C_SALA_S01\": \"temp_sala_s01\",\n",
    "    \"ANALOG_INPUT_C_SALA_S02\": \"temp_sala_s02\"\n",
    "}\n",
    "\n",
    "MAPA_RECT1 = {\n",
    "    \"01_-_VOLTAJE_AC_DEL_SISTEMA\" : \"voltaje_ac_vs\",\n",
    "    \"02_-_VOLTAJE_DC_DEL_SISTEMA\": \"voltaje_dc_vs\",\n",
    "    \"03_-_CORRIENTE_DC_DEL_SISTEMA\": \"corriente_dc_cs\",\n",
    "    \"11_-_CORRIENTE_DC_DE_LA_CARGA\": \"corriente_dc_carga\"\n",
    "}\n",
    "\n",
    "MAPA_RECT2 = {\n",
    "    \"01_-_VOLTAJE_AC_DEL_SISTEMA\" : \"voltaje_ac_vs\",\n",
    "    \"02_-_VOLTAJE_DC_DEL_SISTEMA\": \"voltaje_dc_vs\",\n",
    "    \"03_-_CORRIENTE_DC_DEL_SISTEMA\": \"corriente_dc_cs\",\n",
    "    \"11_-_CORRIENTE_DC_DE_LA_CARGA\": \"corriente_dc_carga\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1340d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_fecha(fecha_str):\n",
    "    \"\"\"\n",
    "    TR - IDEO CALI,\"01 - VOLTAJE AC DEL SISTEMA L1-L2\",\"216.0\",\"V\",\"1/1/2025, 12:50:03 a.Â m.\"\n",
    "\n",
    "    Arregla el formato y elimina caracteres de codificación corruptos (Â).\n",
    "    Entrada: '1/1/2025, 12:00:00 a.Â m.' o '1/1/2025, 12:00:00 a.\\xa0m.'\n",
    "    Salida: '1/1/2025 12:00:00 AM'\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(fecha_str, str):\n",
    "        return str(fecha_str)\n",
    "    \n",
    "\n",
    "    limpia = fecha_str.replace(\"Â\", \"\") \\\n",
    "                      .replace(\"\\xa0\", \" \") \\\n",
    "                      .replace(\",\", \"\") \n",
    "    \n",
    "    limpia = limpia.lower() \\\n",
    "                   .replace(\"a. m.\", \"AM\") \\\n",
    "                   .replace(\"p. m.\", \"PM\") \\\n",
    "                   .replace(\"a.m.\", \"AM\") \\\n",
    "                   .replace(\"p.m.\", \"PM\") \\\n",
    "                   .replace(\"am\", \"AM\") \\\n",
    "                   .replace(\"pm\", \"PM\")\n",
    "    \n",
    "    return limpia.strip() # Eliminar espacios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b09239da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_carpeta_sensor(ruta, nombre_carpeta, nombre_columna_db):\n",
    "    \"\"\"\n",
    "    Lee los 12 meses de una carpeta, limpia y consolida.\n",
    "    \"\"\"\n",
    "\n",
    "    ruta_busqueda = os.path.join(ruta, nombre_carpeta, \"*.csv\") # O *.cvs si tienen error de extension\n",
    "    archivos = glob.glob(ruta_busqueda)\n",
    "    \n",
    "    if not archivos:\n",
    "        print(f\"ADVERTENCIA: No se encontraron archivos en {nombre_carpeta}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Procesando {nombre_carpeta} ({len(archivos)} archivos)...\")\n",
    "    \n",
    "    dfs_meses = []\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        try:\n",
    "            # Leemos el CSV. Importante: dtype=str para no romper la lectura con 'Unplugged'\n",
    "            df_temp = pd.read_csv(archivo, encoding='latin-1', dtype=str) # Probamos latin-1 por los caracteres raros\n",
    "            \n",
    "            df_temp['Time_Clean'] = df_temp['Time'].apply(limpiar_fecha)\n",
    "            df_temp['timestamp'] = pd.to_datetime(df_temp['Time_Clean'], format='%d/%m/%Y %I:%M:%S %p', errors='coerce')\n",
    "            \n",
    "            # Convertimos Value a números. Los textos se vuelven NaN.\n",
    "            df_temp['valor_numerico'] = pd.to_numeric(df_temp['Value'], errors='coerce')\n",
    "            \n",
    "            #Eliminar filas con NaN\n",
    "            df_temp = df_temp.dropna(subset=['valor_numerico', 'timestamp'])\n",
    "            \n",
    "            # Seleccionamos solo lo que sirve (ya limpio)\n",
    "            df_util = df_temp[['timestamp', 'valor_numerico']].copy()\n",
    "            \n",
    "            dfs_meses.append(df_util)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {os.path.basename(archivo)}: {e}\")\n",
    "\n",
    "    if not dfs_meses:\n",
    "        return None\n",
    "\n",
    "    # Unir enero y diciembre \n",
    "    df_anual = pd.concat(dfs_meses, ignore_index=True)\n",
    "    \n",
    "    # Ordenar por fecha\n",
    "    df_anual = df_anual.sort_values('timestamp')\n",
    "    df_anual = df_anual.set_index('timestamp')\n",
    "    \n",
    "\n",
    "    # *************************RESAMPLING (Normalización de tiempo)*******************************************************************\n",
    "    # Como los datos vienen a 12:01:59 y otros a 12:05:00, promediamos cada 10 minutos\n",
    "    # Esto alinea los datos y reduce el ruido.\n",
    "    df_resampled = df_anual.resample('10min').mean()\n",
    "    \n",
    "    # Renombramos la columna 'valor_numerico' al nombre real del sensor (ej: voltaje_ac_l1_l2)\n",
    "    df_resampled.columns = [nombre_columna_db]\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a0f445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESANDO DISPOSITIVO: TR\n",
      "==================================================\n",
      "Procesando 01_VOLTAJE_AC_DEL_SISTEMA_L1_L2 (12 archivos)...\n",
      "Procesando 02_VOLTAJE_AC_DEL_SISTEMA_L2-L3 (12 archivos)...\n",
      "Procesando 03_VOLTAJE_AC_DEL_SISTEMA_L3-L1 (12 archivos)...\n",
      "Procesando 11_CORRIENTE_AC_DE_LA_CARGA_L1 (12 archivos)...\n",
      "Procesando 12_CORRIENTE_AC_DE_LA_CARGA_L2 (12 archivos)...\n",
      "Procesando 13_CORRIENTE_AC_DE_LA_CARGA_L3 (12 archivos)...\n",
      "Procesando 14_POTENCIA_ACTIVA_DE_LA_CARGA (12 archivos)...\n",
      "Procesando 15_POTENCIA_REACTIVA_DE_LA_CARGA (12 archivos)...\n",
      "Procesando 16_POTENCIA_APARENTE_DE_LA_CARGA (12 archivos)...\n",
      "Procesando 17_FACTOR_DE_POTENCIA_DE_LA_CARGA (12 archivos)...\n",
      "Unificando sensores de TR...\n",
      "Guardado consolidado_TR_2025.csv (52560 filas)\n",
      "\n",
      "==================================================\n",
      "PROCESANDO DISPOSITIVO: ML\n",
      "==================================================\n",
      "Procesando ANALOG_INPUT_-_ML_CURRENT_AC_R (12 archivos)...\n",
      "Procesando ANALOG_INPUT_-_ML_CURRENT_AC_S (12 archivos)...\n",
      "Procesando ANALOG_INPUT_-_ML_CURRENT_AC_T (12 archivos)...\n",
      "Procesando ANALOG_INPUT_-_ML_VOLTAGE_AC_R-S (12 archivos)...\n",
      "Procesando ANALOG_INPUT_-_ML_VOLTAGE_AC_S-T (12 archivos)...\n",
      "Procesando ANALOG_INPUT_-_ML_VOLTAGE_AC_T-R (12 archivos)...\n",
      "Procesando ANALOG_INPUT_C_SALA_S01 (12 archivos)...\n",
      "Procesando ANALOG_INPUT_C_SALA_S02 (12 archivos)...\n",
      "Unificando sensores de ML...\n",
      "Guardado consolidado_ML_2025.csv (52560 filas)\n",
      "\n",
      "==================================================\n",
      "PROCESANDO DISPOSITIVO: Rect1\n",
      "==================================================\n",
      "Procesando 01_-_VOLTAJE_AC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 02_-_VOLTAJE_DC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 03_-_CORRIENTE_DC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 11_-_CORRIENTE_DC_DE_LA_CARGA (12 archivos)...\n",
      "Unificando sensores de Rect1...\n",
      "Guardado consolidado_Rect1_2025.csv (52560 filas)\n",
      "\n",
      "==================================================\n",
      "PROCESANDO DISPOSITIVO: Rect2\n",
      "==================================================\n",
      "Procesando 01_-_VOLTAJE_AC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 02_-_VOLTAJE_DC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 03_-_CORRIENTE_DC_DEL_SISTEMA (12 archivos)...\n",
      "Procesando 11_-_CORRIENTE_DC_DE_LA_CARGA (12 archivos)...\n",
      "Unificando sensores de Rect2...\n",
      "Guardado consolidado_Rect2_2025.csv (52560 filas)\n"
     ]
    }
   ],
   "source": [
    "ELEMENTOS_DCE = [\n",
    "    (\"TR\",    \"./Datos/DCE_DATOS_2025/TR\",    MAPA_TR),\n",
    "    (\"ML\",    \"./Datos/DCE_DATOS_2025/ML\",    MAPA_ML),\n",
    "    (\"Rect1\", \"./Datos/DCE_DATOS_2025/Rect1\", MAPA_RECT1),\n",
    "    (\"Rect2\", \"./Datos/DCE_DATOS_2025/Rect2\", MAPA_RECT2)\n",
    "]\n",
    "\n",
    "for nombre_dev, ruta_base, mapa_sensores in ELEMENTOS_DCE:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"PROCESANDO DISPOSITIVO: {nombre_dev}\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    dfs_del_dispositivo = []\n",
    "    \n",
    "\n",
    "    for carpeta_sensor, columna_db in mapa_sensores.items():            \n",
    "        df_sensor = procesar_carpeta_sensor(ruta_base, carpeta_sensor, columna_db)\n",
    "        \n",
    "        if df_sensor is not None:\n",
    "            dfs_del_dispositivo.append(df_sensor)\n",
    "    \n",
    "    if dfs_del_dispositivo:\n",
    "        print(f\"Unificando sensores de {nombre_dev}...\")\n",
    "        df_final = pd.concat(dfs_del_dispositivo, axis=1)\n",
    "        \n",
    "        # Limpieza final (interpolación o reset index)\n",
    "        df_final = df_final.reset_index()\n",
    "        \n",
    "        # Guardar\n",
    "        carpeta_destino = os.path.join(\"Datos\", \"Historico\")\n",
    "        os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "        nombre_archivo = f\"consolidado_{nombre_dev}_2025.csv\"\n",
    "        ruta_completa = os.path.join(carpeta_destino, nombre_archivo)\n",
    "\n",
    "        df_final.to_csv(ruta_completa, index=False)\n",
    "\n",
    "        print(f\"Guardado {nombre_archivo} ({len(df_final)} filas)\")\n",
    "    else:\n",
    "        print(f\"ADVERTENCIA: No se generaron datos para {nombre_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e851a",
   "metadata": {},
   "source": [
    "# Base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "751ade86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33322cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 'root'\n",
    "HOST = 'localhost'\n",
    "PORT = '3306'\n",
    "DB_NAME = 'NODO_IDEO'\n",
    "PASS = \"admin\"\n",
    "#PASS = getpass.getpass(\"contraseña de MySQL: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dd1fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos 'NODO_IDEO' verificada.\n"
     ]
    }
   ],
   "source": [
    "# Cadena de conexión SIN base de datos (para poder crearla)\n",
    "URL_SERVER = f\"mysql+pymysql://{USER}:{PASS}@{HOST}:{PORT}\"\n",
    "# Cadena de conexión CON base de datos (para crear tablas)\n",
    "URL_DB = f\"{URL_SERVER}/{DB_NAME}\"\n",
    "\n",
    "# 1. Conectar al servidor para crear la BD\n",
    "engine_server = create_engine(URL_SERVER)\n",
    "\n",
    "with engine_server.connect() as conn:\n",
    "    # Crea la BD con utf8mb4\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {DB_NAME} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\"))\n",
    "    print(f\"Base de datos '{DB_NAME}' verificada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f135c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_db = create_engine(URL_DB)\n",
    "\n",
    "with engine_db.connect() as conn:\n",
    "\n",
    "    sql_tr = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tr_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_l1_l2 FLOAT,\n",
    "        voltaje_ac_l2_l3 FLOAT,\n",
    "        voltaje_ac_l3_l1 FLOAT,\n",
    "        corriente_ac_l1 FLOAT,\n",
    "        corriente_ac_l2 FLOAT,\n",
    "        corriente_ac_l3 FLOAT,\n",
    "        potencia_activa_kw FLOAT,\n",
    "        potencia_reactiva_kvar FLOAT,\n",
    "        potencia_aparente_kva FLOAT,\n",
    "        factor_potencia FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    sql_ml = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ml_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        corriente_ac_r FLOAT,\n",
    "        corriente_ac_s FLOAT,\n",
    "        corriente_ac_t FLOAT,\n",
    "        voltaje_ac_rs FLOAT,\n",
    "        voltaje_ac_st FLOAT,\n",
    "        voltaje_ac_tr FLOAT,\n",
    "        temp_sala_s01 FLOAT,\n",
    "        temp_sala_s02 FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_rect1 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rect1_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_vs FLOAT,\n",
    "        voltaje_dc_vs FLOAT,\n",
    "        corriente_dc_cs FLOAT,\n",
    "        corriente_dc_carga FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "\n",
    "    sql_rect2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rect2_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_vs FLOAT,\n",
    "        voltaje_dc_vs FLOAT,\n",
    "        corriente_dc_cs FLOAT,\n",
    "        corriente_dc_carga FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    conn.execute(text(sql_tr))\n",
    "    conn.execute(text(sql_ml))\n",
    "    conn.execute(text(sql_rect1))\n",
    "    conn.execute(text(sql_rect2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270b021",
   "metadata": {},
   "source": [
    "# Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85accac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f9b3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_sql(engine_db):\n",
    "\n",
    "    carpeta_origen = os.path.join(\"Datos\", \"Historico\")\n",
    "\n",
    "    mapa_carga = {\n",
    "        \"consolidado_TR_2025.csv\":    \"tr_historico\",\n",
    "        \"consolidado_ML_2025.csv\":    \"ml_historico\",\n",
    "        \"consolidado_Rect1_2025.csv\": \"rect1_historico\",\n",
    "        \"consolidado_Rect2_2025.csv\": \"rect2_historico\"\n",
    "    }\n",
    "\n",
    "    for archivo_csv, nombre_tabla in mapa_carga.items():\n",
    "        ruta_completa = os.path.join(carpeta_origen, archivo_csv)\n",
    "        \n",
    "        # Verificamos si el archivo existe antes de intentar leerlo\n",
    "        if not os.path.exists(ruta_completa):\n",
    "            print(f\" AVISO: No se encontró {archivo_csv}, saltando...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(ruta_completa)\n",
    "            \n",
    "            if 'timestamp' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            \n",
    "            print(f\" Subiendo {len(df)} registros a la tabla '{nombre_tabla}'...\")\n",
    "            \n",
    "            # if_exists='append': Agrega los datos a la tabla que ya creaste.\n",
    "            # index=False: No subir el índice de pandas (0, 1, 2...) como columna.\n",
    "            # chunksize=1000: Sube de a 1000 filas para no saturar la red/memoria.\n",
    "            df.to_sql(\n",
    "                name=nombre_tabla,\n",
    "                con=engine_db,\n",
    "                if_exists='append', \n",
    "                index=False,\n",
    "                chunksize=1000\n",
    "            )\n",
    "            \n",
    "            print(f\"Carga completada en '{nombre_tabla}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" ERROR cargando {nombre_tabla}: {e}\")\n",
    "            # Tip: Si el error es \"Duplicate entry\", significa que ya corriste esto antes.\n",
    "\n",
    "    print(\"\\n PROCESO DE CARGA FINALIZADO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_db = create_engine(URL_DB)\n",
    "cargar_datos_sql(engine_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
