{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f893735",
   "metadata": {},
   "source": [
    "# Transformaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89791993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPA_TR = {\n",
    "    \"01_VOLTAJE_AC_DEL_SISTEMA_L1_L2\": \"voltaje_ac_l1_l2\",\n",
    "    \"02_VOLTAJE_AC_DEL_SISTEMA_L2-L3\": \"voltaje_ac_l2_l3\",\n",
    "    \"03_VOLTAJE_AC_DEL_SISTEMA_L3-L1\": \"voltaje_ac_l3_l1\",\n",
    "    \"11_CORRIENTE_AC_DE_LA_CARGA_L1\": \"corriente_ac_l1\",\n",
    "    \"12_CORRIENTE_AC_DE_LA_CARGA_L2\": \"corriente_ac_l2\",\n",
    "    \"13_CORRIENTE_AC_DE_LA_CARGA_L3\": \"corriente_ac_l3\",\n",
    "    \"14_POTENCIA_ACTIVA_DE_LA_CARGA\": \"potencia_activa_kw\",\n",
    "    \"15_POTENCIA_REACTIVA_DE_LA_CARGA\": \"potencia_reactiva_kvar\",\n",
    "    \"16_POTENCIA_APARENTE_DE_LA_CARGA\": \"potencia_aparente_kva\", \n",
    "    \"17_FACTOR_DE_POTENCIA_DE_LA_CARGA\": \"factor_potencia\"\n",
    "}\n",
    "\n",
    "MAPA_ML = {\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_R\": \"corriente_ac_r\",\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_S\": \"corriente_ac_s\",\n",
    "    \"ANALOG_INPUT_-_ML_CURRENT_AC_T\": \"corriente_ac_t\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_R-S\": \"voltaje_ac_rs\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_S-T\": \"voltaje_ac_st\",\n",
    "    \"ANALOG_INPUT_-_ML_VOLTAGE_AC_T-R\": \"voltaje_ac_tr\",\n",
    "    \"ANALOG_INPUT_C_SALA_S01\": \"temp_sala_s01\",\n",
    "    \"ANALOG_INPUT_C_SALA_S02\": \"temp_sala_s02\"\n",
    "}\n",
    "\n",
    "MAPA_RECT1 = {\n",
    "    \"01_-_VOLTAJE_AC_DEL_SISTEMA\" : \"voltaje_ac_vs\",\n",
    "    \"02_-_VOLTAJE_DC_DEL_SISTEMA\": \"voltaje_dc_vs\",\n",
    "    \"03_-_CORRIENTE_DC_DEL_SISTEMA\": \"corriente_dc_cs\",\n",
    "    \"11_-_CORRIENTE_DC_DE_LA_CARGA\": \"corriente_dc_carga\"\n",
    "}\n",
    "\n",
    "MAPA_RECT2 = {\n",
    "    \"01_-_VOLTAJE_AC_DEL_SISTEMA\" : \"voltaje_ac_vs\",\n",
    "    \"02_-_VOLTAJE_DC_DEL_SISTEMA\": \"voltaje_dc_vs\",\n",
    "    \"03_-_CORRIENTE_DC_DEL_SISTEMA\": \"corriente_dc_cs\",\n",
    "    \"11_-_CORRIENTE_DC_DE_LA_CARGA\": \"corriente_dc_carga\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1340d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_fecha(fecha_str):\n",
    "    \"\"\"\n",
    "    TR - IDEO CALI,\"01 - VOLTAJE AC DEL SISTEMA L1-L2\",\"216.0\",\"V\",\"1/1/2025, 12:50:03 a.√Ç m.\"\n",
    "\n",
    "    Arregla el formato y elimina caracteres de codificaci√≥n corruptos (√Ç).\n",
    "    Entrada: '1/1/2025, 12:00:00 a.√Ç m.' o '1/1/2025, 12:00:00 a.\\xa0m.'\n",
    "    Salida: '1/1/2025 12:00:00 AM'\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(fecha_str, str):\n",
    "        return str(fecha_str)\n",
    "    \n",
    "\n",
    "    limpia = fecha_str.replace(\"√Ç\", \"\") \\\n",
    "                      .replace(\"\\xa0\", \" \") \\\n",
    "                      .replace(\",\", \"\") \n",
    "    \n",
    "    limpia = limpia.lower() \\\n",
    "                   .replace(\"a. m.\", \"AM\") \\\n",
    "                   .replace(\"p. m.\", \"PM\") \\\n",
    "                   .replace(\"a.m.\", \"AM\") \\\n",
    "                   .replace(\"p.m.\", \"PM\") \\\n",
    "                   .replace(\"am\", \"AM\") \\\n",
    "                   .replace(\"pm\", \"PM\")\n",
    "    \n",
    "    return limpia.strip() # Eliminar espacios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b09239da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_carpeta_sensor(ruta, nombre_carpeta, nombre_columna_db):\n",
    "    \n",
    "    ruta_busqueda = os.path.join(ruta, nombre_carpeta, \"*.csv\") \n",
    "    archivos = glob.glob(ruta_busqueda)\n",
    "    \n",
    "    if not archivos:\n",
    "        print(f\"ADVERTENCIA: No se encontraron archivos en {nombre_carpeta}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Procesando {nombre_carpeta} ({len(archivos)} archivos)...\")\n",
    "    \n",
    "    dfs_meses = []\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        try:\n",
    "            # Leemos el CSV. Importante: dtype=str para no romper la lectura con 'Unplugged'\n",
    "            df_temp = pd.read_csv(archivo, encoding='latin-1', dtype=str) # Probamos latin-1 por los caracteres raros\n",
    "            \n",
    "            df_temp['Time_Clean'] = df_temp['Time'].apply(limpiar_fecha)\n",
    "            df_temp['timestamp'] = pd.to_datetime(df_temp['Time_Clean'], format='%d/%m/%Y %I:%M:%S %p', errors='coerce')\n",
    "            \n",
    "            # Convertimos Value a n√∫meros. Los textos se vuelven NaN.\n",
    "            df_temp['valor_numerico'] = pd.to_numeric(df_temp['Value'], errors='coerce')\n",
    "            \n",
    "            #Eliminar filas con NaN\n",
    "            df_temp = df_temp.dropna(subset=['valor_numerico', 'timestamp'])\n",
    "            \n",
    "            # Seleccionamos solo lo que sirve (ya limpio)\n",
    "            df_util = df_temp[['timestamp', 'valor_numerico']].copy()\n",
    "            \n",
    "            dfs_meses.append(df_util)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error leyendo {os.path.basename(archivo)}: {e}\")\n",
    "\n",
    "    if not dfs_meses:\n",
    "        return None\n",
    "\n",
    "    # Unir enero y diciembre \n",
    "    df_anual = pd.concat(dfs_meses, ignore_index=True)\n",
    "    \n",
    "    # Ordenar por fecha\n",
    "    df_anual = df_anual.sort_values('timestamp')\n",
    "    df_anual = df_anual.set_index('timestamp')\n",
    "    \n",
    "\n",
    "    # *************************RESAMPLING (Normalizaci√≥n de tiempo)*******************************************************************\n",
    "    # Como los datos vienen a 12:01:59 y otros a 12:05:00, promediamos cada 10 minutos\n",
    "    # Esto alinea los datos y reduce el ruido.\n",
    "    df_resampled = df_anual.resample('10min').mean()\n",
    "    \n",
    "    # Renombramos la columna 'valor_numerico' al nombre real del sensor (ej: voltaje_ac_l1_l2)\n",
    "    df_resampled.columns = [nombre_columna_db]\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a0f445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROCESANDO DISPOSITIVO: TR\n",
      "==================================================\n",
      "Procesando 01_VOLTAJE_AC_DEL_SISTEMA_L1_L2 (12 archivos)...\n",
      "Procesando 02_VOLTAJE_AC_DEL_SISTEMA_L2-L3 (12 archivos)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m dfs_del_dispositivo = []\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m carpeta_sensor, columna_db \u001b[38;5;129;01min\u001b[39;00m mapa_sensores.items():            \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     df_sensor = \u001b[43mprocesar_carpeta_sensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarpeta_sensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumna_db\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df_sensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     20\u001b[39m         dfs_del_dispositivo.append(df_sensor)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mprocesar_carpeta_sensor\u001b[39m\u001b[34m(ruta, nombre_carpeta, nombre_columna_db)\u001b[39m\n\u001b[32m     17\u001b[39m df_temp = pd.read_csv(archivo, encoding=\u001b[33m'\u001b[39m\u001b[33mlatin-1\u001b[39m\u001b[33m'\u001b[39m, dtype=\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;66;03m# Probamos latin-1 por los caracteres raros\u001b[39;00m\n\u001b[32m     19\u001b[39m df_temp[\u001b[33m'\u001b[39m\u001b[33mTime_Clean\u001b[39m\u001b[33m'\u001b[39m] = df_temp[\u001b[33m'\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m'\u001b[39m].apply(limpiar_fecha)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df_temp[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_temp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTime_Clean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm/\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mI:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mS \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Convertimos Value a n√∫meros. Los textos se vuelven NaN.\u001b[39;00m\n\u001b[32m     23\u001b[39m df_temp[\u001b[33m'\u001b[39m\u001b[33mvalor_numerico\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df_temp[\u001b[33m'\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1071\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_string_array(result):\n\u001b[32m    483\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(result, dtype=\u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m, name=name)\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:566\u001b[39m, in \u001b[36mIndex.__new__\u001b[39m\u001b[34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[39m\n\u001b[32m    563\u001b[39m         data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     arr = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mindex must be specified when data is not list-like\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\construction.py:622\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, allow_2d)\u001b[39m\n\u001b[32m    618\u001b[39m             subarr = subarr.copy()\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;66;03m# we will try to copy by-definition here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m         subarr = \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[33m\"\u001b[39m\u001b[33m__array__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[32m    626\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\construction.py:808\u001b[39m, in \u001b[36m_try_cast\u001b[39m\u001b[34m(arr, dtype, copy)\u001b[39m\n\u001b[32m    803\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(arr, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m, copy=copy).reshape(\n\u001b[32m    804\u001b[39m         shape\n\u001b[32m    805\u001b[39m     )\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaybe_cast_to_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# GH#15832: Check if we are requesting a numeric dtype and\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# that we can convert the data to the requested dtype.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    813\u001b[39m     \u001b[38;5;66;03m# this will raise if we have e.g. floats\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1237\u001b[39m, in \u001b[36mmaybe_cast_to_datetime\u001b[39m\u001b[34m(value, dtype)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m         dta = \u001b[43mDatetimeArray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1238\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1239\u001b[39m         \u001b[38;5;66;03m# We can give a Series-specific exception message.\u001b[39;00m\n\u001b[32m   1240\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcannot supply both a tz and a timezone-naive dtype\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:329\u001b[39m, in \u001b[36mDatetimeArray._from_sequence\u001b[39m\u001b[34m(cls, scalars, dtype, copy)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_sequence\u001b[39m(\u001b[38;5;28mcls\u001b[39m, scalars, *, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_sequence_not_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhoyosme\\Desktop\\Proyecto\\Program\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:331\u001b[39m, in \u001b[36mDatetimeArray._from_sequence_not_strict\u001b[39m\u001b[34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_sequence\u001b[39m(\u001b[38;5;28mcls\u001b[39m, scalars, *, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._from_sequence_not_strict(scalars, dtype=dtype, copy=copy)\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_sequence_not_strict\u001b[39m(\n\u001b[32m    333\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m    334\u001b[39m     data,\n\u001b[32m    335\u001b[39m     *,\n\u001b[32m    336\u001b[39m     dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    337\u001b[39m     copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    338\u001b[39m     tz=lib.no_default,\n\u001b[32m    339\u001b[39m     freq: \u001b[38;5;28mstr\u001b[39m | BaseOffset | lib.NoDefault | \u001b[38;5;28;01mNone\u001b[39;00m = lib.no_default,\n\u001b[32m    340\u001b[39m     dayfirst: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    341\u001b[39m     yearfirst: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    342\u001b[39m     ambiguous: TimeAmbiguous = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    343\u001b[39m ) -> Self:\n\u001b[32m    344\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03m    A non-strict version of _from_sequence, called from DatetimeIndex.__new__.\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    348\u001b[39m     \u001b[38;5;66;03m# if the user either explicitly passes tz=None or a tz-naive dtype, we\u001b[39;00m\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m#  disallows inferring a tz.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ELEMENTOS_DCE = [\n",
    "    (\"TR\",    \"./Datos/DCE_DATOS_2025/TR\",    MAPA_TR),\n",
    "    (\"ML\",    \"./Datos/DCE_DATOS_2025/ML\",    MAPA_ML),\n",
    "    (\"Rect1\", \"./Datos/DCE_DATOS_2025/Rect1\", MAPA_RECT1),\n",
    "    (\"Rect2\", \"./Datos/DCE_DATOS_2025/Rect2\", MAPA_RECT2)\n",
    "]\n",
    "\n",
    "for nombre_dev, ruta_base, mapa_sensores in ELEMENTOS_DCE:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"PROCESANDO DISPOSITIVO: {nombre_dev}\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    dfs_del_dispositivo = []\n",
    "    \n",
    "\n",
    "    for carpeta_sensor, columna_db in mapa_sensores.items():            \n",
    "        df_sensor = procesar_carpeta_sensor(ruta_base, carpeta_sensor, columna_db)\n",
    "        \n",
    "        if df_sensor is not None:\n",
    "            dfs_del_dispositivo.append(df_sensor)\n",
    "    \n",
    "    if dfs_del_dispositivo:\n",
    "        print(f\"Unificando sensores de {nombre_dev}...\")\n",
    "        df_final = pd.concat(dfs_del_dispositivo, axis=1)\n",
    "        \n",
    "        # Limpieza final (interpolaci√≥n o reset index)\n",
    "        df_final = df_final.reset_index()\n",
    "        \n",
    "        # Guardar\n",
    "        carpeta_destino = os.path.join(\"Datos\", \"Historico\")\n",
    "        os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "        nombre_archivo = f\"consolidado_{nombre_dev}_2025.csv\"\n",
    "        ruta_completa = os.path.join(carpeta_destino, nombre_archivo)\n",
    "\n",
    "        df_final.to_csv(ruta_completa, index=False)\n",
    "\n",
    "        print(f\"Guardado {nombre_archivo} ({len(df_final)} filas)\")\n",
    "    else:\n",
    "        print(f\"ADVERTENCIA: No se generaron datos para {nombre_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e851a",
   "metadata": {},
   "source": [
    "# Base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ade86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33322cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 'root'\n",
    "HOST = 'localhost'\n",
    "PORT = '3306'\n",
    "DB_NAME = 'NODO_IDEO'\n",
    "PASS = getpass.getpass(\"contrase√±a de MySQL: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos 'NODO_IDEO' verificada.\n"
     ]
    }
   ],
   "source": [
    "# Cadena de conexi√≥n SIN base de datos (para poder crearla)\n",
    "URL_SERVER = f\"mysql+pymysql://{USER}:{PASS}@{HOST}:{PORT}\"\n",
    "# Cadena de conexi√≥n CON base de datos (para crear tablas)\n",
    "URL_DB = f\"{URL_SERVER}/{DB_NAME}\"\n",
    "\n",
    "# Conectar al servidor para crear la BD\n",
    "engine_server = create_engine(URL_SERVER)\n",
    "\n",
    "with engine_server.connect() as conn:\n",
    "    # Crea la BD con utf8mb4\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {DB_NAME} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\"))\n",
    "    print(f\"Base de datos '{DB_NAME}' verificada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_db = create_engine(URL_DB)\n",
    "\n",
    "with engine_db.connect() as conn:\n",
    "\n",
    "    sql_tr = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tr_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_l1_l2 FLOAT,\n",
    "        voltaje_ac_l2_l3 FLOAT,\n",
    "        voltaje_ac_l3_l1 FLOAT,\n",
    "        corriente_ac_l1 FLOAT,\n",
    "        corriente_ac_l2 FLOAT,\n",
    "        corriente_ac_l3 FLOAT,\n",
    "        potencia_activa_kw FLOAT,\n",
    "        potencia_reactiva_kvar FLOAT,\n",
    "        potencia_aparente_kva FLOAT,\n",
    "        factor_potencia FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    sql_ml = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ml_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        corriente_ac_r FLOAT,\n",
    "        corriente_ac_s FLOAT,\n",
    "        corriente_ac_t FLOAT,\n",
    "        voltaje_ac_rs FLOAT,\n",
    "        voltaje_ac_st FLOAT,\n",
    "        voltaje_ac_tr FLOAT,\n",
    "        temp_sala_s01 FLOAT,\n",
    "        temp_sala_s02 FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_rect1 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rect1_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_vs FLOAT,\n",
    "        voltaje_dc_vs FLOAT,\n",
    "        corriente_dc_cs FLOAT,\n",
    "        corriente_dc_carga FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "\n",
    "    sql_rect2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rect2_historico (\n",
    "        timestamp DATETIME NOT NULL,\n",
    "        voltaje_ac_vs FLOAT,\n",
    "        voltaje_dc_vs FLOAT,\n",
    "        corriente_dc_cs FLOAT,\n",
    "        corriente_dc_carga FLOAT,\n",
    "        PRIMARY KEY (timestamp)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "\n",
    "    conn.execute(text(sql_tr))\n",
    "    conn.execute(text(sql_ml))\n",
    "    conn.execute(text(sql_rect1))\n",
    "    conn.execute(text(sql_rect2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270b021",
   "metadata": {},
   "source": [
    "# Carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85accac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4cf14b",
   "metadata": {},
   "source": [
    "## DCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_sql(engine_db):\n",
    "\n",
    "    carpeta_origen = os.path.join(\"Datos\", \"Historico\")\n",
    "\n",
    "    mapa_carga = {\n",
    "        \"consolidado_TR_2025.csv\":    \"tr_historico\",\n",
    "        \"consolidado_ML_2025.csv\":    \"ml_historico\",\n",
    "        \"consolidado_Rect1_2025.csv\": \"rect1_historico\",\n",
    "        \"consolidado_Rect2_2025.csv\": \"rect2_historico\"\n",
    "    }\n",
    "\n",
    "    for archivo_csv, nombre_tabla in mapa_carga.items():\n",
    "        ruta_completa = os.path.join(carpeta_origen, archivo_csv)\n",
    "        \n",
    "        if not os.path.exists(ruta_completa):\n",
    "            print(f\" AVISO: No se encontr√≥ {archivo_csv}, saltando...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(ruta_completa)\n",
    "            \n",
    "            if 'timestamp' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            \n",
    "            print(f\" Subiendo {len(df)} registros a la tabla '{nombre_tabla}'...\")\n",
    "            \n",
    "            # if_exists='append': Agrega los datos a la tabla que ya creaste.\n",
    "            # index=False: No subir el √≠ndice de pandas (0, 1, 2...) como columna.\n",
    "            # chunksize=1000: Sube de a 1000 filas para no saturar la red/memoria.\n",
    "            df.to_sql(\n",
    "                name=nombre_tabla,\n",
    "                con=engine_db,\n",
    "                if_exists='append', \n",
    "                index=False,\n",
    "                chunksize=1000\n",
    "            )\n",
    "            \n",
    "            print(f\"Carga completada en '{nombre_tabla}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" ERROR cargando {nombre_tabla}: {e}\")\n",
    "            # Tip: Si el error es \"Duplicate entry\", significa que ya corriste esto antes.\n",
    "\n",
    "    print(\"\\n PROCESO DE CARGA FINALIZADO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Subiendo 52560 registros a la tabla 'tr_historico'...\n",
      "Carga completada en 'tr_historico'.\n",
      " Subiendo 52560 registros a la tabla 'ml_historico'...\n",
      "Carga completada en 'ml_historico'.\n",
      " Subiendo 52560 registros a la tabla 'rect1_historico'...\n",
      "Carga completada en 'rect1_historico'.\n",
      " Subiendo 52560 registros a la tabla 'rect2_historico'...\n",
      "Carga completada en 'rect2_historico'.\n",
      "\n",
      " PROCESO DE CARGA FINALIZADO.\n"
     ]
    }
   ],
   "source": [
    "cargar_datos_sql(engine_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498f540",
   "metadata": {},
   "source": [
    "## Datos Manuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_db = create_engine(URL_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informacion de nodo actualizada\n",
      "inventario AC actualizada\n",
      "inventario PDB actualizada\n"
     ]
    }
   ],
   "source": [
    "archivo_excel = \"Datos/datos_manuales.xlsx\"\n",
    "\n",
    "with engine_db.connect() as conn:\n",
    "    \n",
    "    # INFO_NODO\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS info_nodo\"))\n",
    "    sql_info = \"\"\"\n",
    "    CREATE TABLE info_nodo (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        nombre_nodo VARCHAR(50),\n",
    "        tipo VARCHAR(10),\n",
    "        codigo VARCHAR(50),\n",
    "        regional VARCHAR(50),\n",
    "        direccion VARCHAR(100),\n",
    "        capacidad_kva FLOAT,\n",
    "        voltaje_sistema_dc FLOAT\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    conn.execute(text(sql_info))\n",
    "    \n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(archivo_excel, sheet_name=\"info_nodo\")\n",
    "        df.to_sql('info_nodo', con=engine_db, if_exists='append', index=False)\n",
    "        print(\"Informacion de nodo actualizada\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando datos: {e}\")\n",
    "\n",
    "\n",
    "    # INVENTARIO_AC\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS inventario_ac\"))\n",
    "    \n",
    "    sql_ac = \"\"\"\n",
    "    CREATE TABLE inventario_ac (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        ubicacion VARCHAR(50),\n",
    "        componente VARCHAR(50),      \n",
    "        marca VARCHAR(50),           \n",
    "        referencia VARCHAR(100),     \n",
    "        capacidad_amps FLOAT,        \n",
    "        calibre_cable VARCHAR(50) \n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    conn.execute(text(sql_ac))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(archivo_excel, sheet_name=\"inventario_ac\")\n",
    "        df.to_sql('inventario_ac', con=engine_db, if_exists='append', index=False)\n",
    "        print(\"inventario AC actualizada\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando datos: {e}\")\n",
    "\n",
    "\n",
    "    # INVENTARIO_DC_PDB\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS inventario_dc_pdb\"))\n",
    "    \n",
    "    sql_pdb = \"\"\"\n",
    "    CREATE TABLE inventario_dc_pdb (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        pdb_nombre VARCHAR(20),      \n",
    "        fuente VARCHAR(10),          \n",
    "        posicion INT,       \n",
    "        estado VARCHAR(20),          \n",
    "        capacidad FLOAT,\n",
    "        corriente FLOAT,\n",
    "        equipo_refencia VARCHAR(100) \n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    conn.execute(text(sql_pdb))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(archivo_excel, sheet_name=\"inventario_pdb\")\n",
    "        df.to_sql('inventario_dc_pdb', con=engine_db, if_exists='append', index=False)\n",
    "        print(\"inventario PDB actualizada\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando datos: {e}\")\n",
    "        \n",
    "    # Confirmar cambios de estructura\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797be49",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3  \n",
    "\n",
    "# silencia la advertencia roja\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "response = requests.get(\"https://10.159.125.33\", verify=False, timeout=5)\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e9b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ Enviando GET a: https://10.159.125.33/isxg/v1/devices\n",
      "C√≥digo HTTP: 200\n",
      "\n",
      "‚úÖ Respuesta OK (primeros 500 caracteres):\n",
      "\n",
      "[{\"severity\":0,\"severityText\":\"None\",\"inMaintenance\":false,\"isxcGuid\":\"B7e755e_nbSNMPEncFA60E49D\",\"model\":\"AP8461\",\"type\":\"Rack PDU\",\"hostname\":\"10.170.118.126\",\"ipAddress\":\"10.170.118.126\",\"privateSide\":false,\"label\":\"EPM-L25-PDU-DER\",\"serialNumber\":\"5A1946E02998\",\"location\":\"SALA 03 - RACK L25\",\"supplemental\":{\"InputPhaseCount\":3,\"OutputPhaseCount\":3}},{\"severity\":0,\"severityText\":\"None\",\"inMaintenance\":false,\"isxcGuid\":\"B7e755e_nbSNMPEnc88F4D655\",\"model\":\"EATON - SC200\",\"type\":\"DC Rectifier\",\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "\n",
    "# Deshabilitar advertencias SSL \n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "DCE_HOST = \"https://10.159.125.33\"  \n",
    "ACCESS_TOKEN = \"954ff0a0-4e9a-48b3-b124-321f86f923e3\"   \n",
    "\n",
    "\n",
    "url = f\"{DCE_HOST}/isxg/v1/devices\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "}\n",
    "\n",
    "print(\"Enviando GET a:\", url)\n",
    "\n",
    "response = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "print(\"C√≥digo HTTP:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"\\nRespuesta OK (primeros 500 caracteres):\\n\")\n",
    "    print(response.text[:500])\n",
    "else:\n",
    "    print(\"\\nError:\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ec2fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Buscando la puerta de entrada correcta para el usuario 'mhoyosme'...\n",
      "üëâ Probando: https://10.159.125.33/api/v1/oauth/token ... ‚ùå (404 Not Found - Ruta equivocada)\n",
      "üëâ Probando: https://10.159.125.33/isxg/api/v1/oauth/token ... ‚õî (401 Unauthorized - Ruta existe pero rechaz√≥ credenciales)\n",
      "üëâ Probando: https://10.159.125.33/isxg/oauth/token ... ‚úÖ ¬°√âXITO! (200 OK)\n",
      "   üéâ ¬°Encontramos la URL correcta!\n",
      "--------------------------------------------------\n",
      "üèÜ LA URL QUE DEBES USAR EN TU SCRIPT ES:\n",
      "\n",
      "self.auth_url = \"https://10.159.125.33/isxg/oauth/token\"\n",
      "\n",
      "Copia esa l√≠nea y p√©gala en tu clase GestorDCE.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import getpass\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# --- TUS DATOS ---\n",
    "IP = \"10.159.125.33\"\n",
    "USUARIO = \"mhoyosme\"\n",
    "PASSWORD = getpass.getpass(\"üîë Ingresa tu contrase√±a una vez m√°s: \")\n",
    "\n",
    "# Lista de todas las posibles direcciones de Login de DCE\n",
    "rutas_a_probar = [\n",
    "    f\"https://{IP}/api/v1/oauth/token\",        # Opci√≥n Est√°ndar Moderna\n",
    "    f\"https://{IP}/isxg/api/v1/oauth/token\",   # Opci√≥n con prefijo ISXG\n",
    "    f\"https://{IP}/isxg/oauth/token\",          # Opci√≥n versiones intermedias\n",
    "    f\"https://{IP}/oauth/token\",               # Opci√≥n ra√≠z\n",
    "    f\"https://{IP}/rest/oauth/token\"           # Opci√≥n antigua\n",
    "]\n",
    "\n",
    "print(f\"\\nüîç Buscando la puerta de entrada correcta para el usuario '{USUARIO}'...\")\n",
    "\n",
    "payload = {\n",
    "    \"username\": USUARIO,\n",
    "    \"password\": PASSWORD,\n",
    "    \"grant_type\": \"password\"\n",
    "}\n",
    "\n",
    "url_ganadora = None\n",
    "\n",
    "for url in rutas_a_probar:\n",
    "    print(f\"üëâ Probando: {url} ...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        # Probamos enviar los datos como FORM (data=...) que es lo est√°ndar en OAuth\n",
    "        response = requests.post(url, data=payload, verify=False, timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ ¬°√âXITO! (200 OK)\")\n",
    "            print(\"   üéâ ¬°Encontramos la URL correcta!\")\n",
    "            url_ganadora = url\n",
    "            break # Dejamos de buscar\n",
    "        elif response.status_code == 404:\n",
    "            print(\"‚ùå (404 Not Found - Ruta equivocada)\")\n",
    "        elif response.status_code == 401:\n",
    "            print(\"‚õî (401 Unauthorized - Ruta existe pero rechaz√≥ credenciales)\")\n",
    "            # A veces el 401 aqu√≠ significa que la ruta es correcta pero el formato no\n",
    "            # Pero sigamos buscando por si acaso hay un 200 en otra.\n",
    "        elif response.status_code == 405:\n",
    "            print(\"üö´ (405 Method Not Allowed - Ruta equivocada)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è ({response.status_code})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"üíÄ Error de conexi√≥n: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if url_ganadora:\n",
    "    print(f\"üèÜ LA URL QUE DEBES USAR EN TU SCRIPT ES:\\n\")\n",
    "    print(f'self.auth_url = \"{url_ganadora}\"')\n",
    "    print(\"\\nCopia esa l√≠nea y p√©gala en tu clase GestorDCE.\")\n",
    "else:\n",
    "    print(\"‚ùå Ninguna ruta funcion√≥ est√°ndar. Posibles causas:\")\n",
    "    print(\"1. La contrase√±a se escribi√≥ mal en este intento.\")\n",
    "    print(\"2. El servidor requiere un encabezado 'Content-Type' espec√≠fico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando equipos en: https://10.159.125.33/isxg/v1/devices...\n",
      "Total de equipos en el servidor: 1337\n",
      "\n",
      "EQUIPOS ENCONTRADOS (IDEO / CALI):\n",
      "NOMBRE (Label)                           | MODELO                    | ID √öNICO (isxcGuid)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RECT 02 - IDEO CALI - (10.170.203.7)     | ELTEK - SMARTPACK 2 TOUCH | B7e755e_nbSNMPEnc7D425FC9\n",
      "TABLERO - IDEO CALI - (10.170.203.2)     | EATON - SC200             | B7e755e_nbSNMPEnc60BA612C\n",
      "MG - IDEO CALI                           | COMAP - INTELILITE AMF25 - MRS - 3P | B7e755e_nbModbusEnc11703964\n",
      "RECT 01 - IDEO CALI - (10.170.203.6)     | ELTEK - SMARTPACK 2 TOUCH | B7e755e_nbSNMPEncD1F128BD\n",
      "TR - IDEO CALI                           | COMAP - IL-NT-AMF25 - 3P  | B7e755e_nbModbusEnc4B4D008D\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "IP = \"10.159.125.33\"\n",
    "TOKEN = \"e264daff-a662-410b-891d-514508c0fb3a\" \n",
    "URL_DEVICES = f\"https://{IP}/isxg/v1/devices\"\n",
    "\n",
    "def buscar_equipos_ideo():\n",
    "    print(f\"Buscando equipos en: {URL_DEVICES}...\")\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL_DEVICES, headers=headers, verify=False, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            todos_los_equipos = response.json()\n",
    "            print(f\"Total de equipos en el servidor: {len(todos_los_equipos)}\")\n",
    "            \n",
    "            mis_equipos = []\n",
    "            \n",
    "            print(f\"{'NOMBRE (Label)':<40} | {'MODELO':<25} | {'ID √öNICO (isxcGuid)'}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            for equipo in todos_los_equipos:\n",
    "                label = equipo.get('label', 'Sin Nombre')\n",
    "                \n",
    "                label_up = label.upper()\n",
    "\n",
    "                if re.search(r'\\bIDEO\\b', label_up) or re.search(r'\\bCALI\\b', label_up):\n",
    "                    modelo = equipo.get('model', 'N/A')\n",
    "                    guid = equipo.get('isxcGuid')\n",
    "\n",
    "                    print(f\"{label:<40} | {modelo:<25} | {guid}\")\n",
    "\n",
    "                    mis_equipos.append({\n",
    "                        \"Nombre\": label,\n",
    "                        \"ID\": guid,\n",
    "                        \"Modelo\": modelo\n",
    "                    })\n",
    "                            \n",
    "            if not mis_equipos:\n",
    "                print(\"No encontr√© equipos con la palabra 'IDEO' o 'CALI'. Revisa c√≥mo est√°n nombrados.\")\n",
    "            \n",
    "            return mis_equipos\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error de conexi√≥n: {e}\")\n",
    "\n",
    "\n",
    "equipos = buscar_equipos_ideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24edc48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Consultando (B7e755e_nbSNMPEnc60BA612C)...\n",
      "Renovando Token de acceso...\n",
      "Token renovado exitosamente.\n",
      "Se recibieron 12 sensores.\n",
      "SENSORES                                          \n",
      "------------------------------------------------------------\n",
      "ANALOG INPUT - ML CURRENT AC S 70.50 A AMP_DETECTOR\n",
      "ANALOG INPUT - ML CURRENT AC T 82.10 A AMP_DETECTOR\n",
      "ANALOG INPUT - ¬∞C SALA S01 24.00 ¬∞ C TEMPERATURE\n",
      "ANALOG INPUT - ML VOLTAGE AC R-S 213.86 V VOLTAGE\n",
      "ANALOG INPUT - ML VOLTAGE AC S-T 213.30 V VOLTAGE\n",
      "08 - CORRIENTE DC DE LAS BATERIAS 0.00 A AMP_DETECTOR\n",
      "Link Status Online COMMUNICATION_SENSOR\n",
      "ANALOG INPUT - ML VOLTAGE AC T-R 218.78 V VOLTAGE\n",
      "ANALOG INPUT - ML CURRENT AC R 70.39 A AMP_DETECTOR\n",
      "DIGITAL OUTPUT - ML AC FAIL INACTIVO STATE\n",
      "ANALOG INPUT - ¬∞C SALA S02 21.00 ¬∞ C TEMPERATURE\n",
      "13 - TEST DE BATERIAS DESHABILITADO STATE\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import time\n",
    "import getpass\n",
    "\n",
    "# Desactivar alertas SSL\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "class GestorDCE:\n",
    "    def __init__(self, ip, usuario, password):\n",
    "        self.base_url = f\"https://{ip}/isxg/v1\"       \n",
    "        self.auth_url = f\"https://{ip}/isxg/oauth/token\"\n",
    "        self.usuario = usuario\n",
    "        self.password = password\n",
    "        self.token = None\n",
    "        self.token_time = 0\n",
    "        self.TTL = 250  # 4 minutos de vida √∫til (renueva antes de los 5 min)\n",
    "\n",
    "    def _obtener_nuevo_token(self):\n",
    "        \"\"\"Pide un token nuevo autom√°ticamente\"\"\"\n",
    "        print(\"Renovando Token de acceso...\")\n",
    "        \n",
    "        # Datos para OAuth2\n",
    "        payload = {\n",
    "            \"username\": self.usuario,\n",
    "            \"password\": self.password,\n",
    "            \"grant_type\": \"password\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            resp = requests.post(self.auth_url, data=payload, verify=False, timeout=15)\n",
    "            \n",
    "            if resp.status_code == 200:\n",
    "                data = resp.json()\n",
    "                self.token = data['access_token']\n",
    "                self.token_time = time.time()\n",
    "                print(\"Token renovado exitosamente.\")\n",
    "            else:\n",
    "                # Si falla, imprimimos el error crudo para depurar\n",
    "                raise Exception(f\"Error Login ({resp.status_code}): {resp.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error cr√≠tico obteniendo token: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def get_headers(self):\n",
    "        \"\"\"Devuelve las cabeceras con un token v√°lido\"\"\"\n",
    "        ahora = time.time()\n",
    "        # Si no hay token o ya casi vence, pedimos uno nuevo\n",
    "        if not self.token or (ahora - self.token_time > self.TTL):\n",
    "            self._obtener_nuevo_token()\n",
    "        \n",
    "        return {\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "\n",
    "    def consultar_equipo(self, device_id):\n",
    "        \"\"\"Consulta todos los sensores de un equipo\"\"\"\n",
    "        endpoint = f\"{self.base_url}/devices/{device_id}/sensors\"\n",
    "        \n",
    "        try:\n",
    "            headers = self.get_headers() # Aqu√≠ se hace el login autom√°tico si hace falta\n",
    "            resp = requests.get(endpoint, headers=headers, verify=False, timeout=15)\n",
    "            \n",
    "            if resp.status_code == 200:\n",
    "                return resp.json()\n",
    "            else:\n",
    "                print(f\" Error consultando equipo {device_id}: {resp.status_code}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\" Error de conexi√≥n consultando equipo: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# PRUEBA FINAL EN TIEMPO REAL\n",
    "if __name__ == \"__main__\":\n",
    "    IP = \"10.159.125.33\"\n",
    "    USER = \"mhoyosme\"\n",
    "    PASS = getpass.getpass(\" Contrase√±a: \") \n",
    "\n",
    "    dce = GestorDCE(IP, USER, PASS)\n",
    "\n",
    "    id_tr = \"B7e755e_nbSNMPEnc60BA612C\" \n",
    "             #B7e755e_nbModbusEnc4B4D008D\n",
    "    \n",
    "    \n",
    "    print(f\"\\n Consultando ({id_tr})...\")\n",
    "    sensores = dce.consultar_equipo(id_tr)\n",
    "\n",
    "    if sensores:\n",
    "        print(f\"Se recibieron {len(sensores)} sensores.\")\n",
    "        print(f\"{'SENSORES':<50}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for s in sensores:\n",
    "            label = s.get('label', 'N/A')\n",
    "            valor = s.get('value', 'N/A')\n",
    "            unidad = s.get('units', '')\n",
    "            kind = s.get('kind', '')\n",
    "            \n",
    "            print(f\"{label} {valor} {kind}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
